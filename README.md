# Narrating the Unseen Real-Time Video Descriptions for Visually Impaired Individuals

This research explores a novel system 
designed to empower visually impaired individuals by narrating 
their surroundings through spoken language, leveraging the 
capabilities of a mobile camera. Our study involves a comparative 
analysis of various pre-trained models in generating descriptive 
captions. Globally, approximately 2.2 billion people are affected 
by some form of visual impairment or blindness. Addressing this 
significant challenge, our research proposes an integrated solution 
aimed at assisting visually impaired individuals in comprehending 
their environment. This is achieved through the description of 
video streams, utilizing advanced Generative AI techniques.

The cornerstone of our proposed methodology is the use of a 
pre-trained GPT-4 Vision multimodal model, which has been 
trained on an extensive dataset comprising 13 million tokens. 
Additionally, we have engineered a robust Client-Server socket 
connection framework. This design ensures that intensive 
computational tasks, particularly video stream preprocessing, are 
primarily conducted server-side.

A key aspect of our research involves the evaluation of 
generated captions. These are meticulously compared with 
standard captions using established metrics such as BLEU and 
ROUGE scores. Recognizing the semantic limitations inherent in 
these metrics, we also employ a Semantic Similarity metric for a 
more nuanced comparison. This comprehensive approach allows 
for a thorough assessment of the effectiveness of our system in 
providing accurate and contextually relevant descriptions for the 
visually impaired.

Referenes:

- [Image Captioning Paper and Codes](https://paperswithcode.com/task/image-captioning)
- [Semi-Autoregressive Image Captioning](https://paperswithcode.com/paper/semi-autoregressive-image-captioning)
- [DeeCap: Dynamic Early Exiting for Efficient Image Captioning](https://paperswithcode.com/paper/deecap-dynamic-early-exiting-for-efficient)
- [SpeechCLIP: Integrating Speech with Pre-Trained Vision and Language Model](https://paperswithcode.com/paper/speechclip-integrating-speech-with-pre)
- [Show, Translate and Tell](https://paperswithcode.com/paper/show-translate-and-tell)
- [Guided Open Vocabulary Image Captioning with Constrained Beam Search](https://paperswithcode.com/paper/guided-open-vocabulary-image-captioning-with)
- [A Picture is Worth a Thousand Words: A Unified System for Diverse Captions and Rich Images Generation](https://paperswithcode.com/paper/a-picture-is-worth-a-thousand-words-a-unified)
- [AVLnet: Learning Audio-Visual Language Representations from Instructional Videos](https://paperswithcode.com/paper/avlnet-learning-audio-visual-language#tasks)
- [NICE: CVPR 2023 Challenge on Zero-shot Image Captioning](https://paperswithcode.com/paper/nice-2023-zero-shot-image-captioning)
- [Enhancing image captioning with depth information using a Transformer-based framework](https://openreview.net/forum?id=PtrK8Aoe2M&referrer=%5BTMLR%5D(%2Fgroup%3Fid%3DTMLR))
- [Current challenges and limitations of image captioning](https://www.linkedin.com/advice/0/what-current-challenges-limitations-image-captioning)
- [How to Develop a Deep Learning Photo Caption Generator from Scratch](https://machinelearningmastery.com/develop-a-deep-learning-caption-generation-model-in-python/)
- [Generating image captions from the camera feed](https://subscription.packtpub.com/book/data/9781789611212/5/ch05lvl1sec44/generating-image-captions-from-the-camera-feed)
- [A Real-time Image Caption Generator based on Jetson nano](https://www.youtube.com/watch?v=1CCw9bJy5w8&ab_channel=DeepLearningUSC)
- [Exploring Deep Learning Image Captioning](https://mobidev.biz/blog/exploring-deep-learning-image-captioning)
- [Image captioning using CRNN encoding in seq2seq model](https://medium.com/@aromalma/image-captioning-using-crnn-encoding-in-seq2seq-model-808bf67f2d6a)
- [Step by Step Guide to Build Image Caption Generator using Deep Learning](https://www.analyticsvidhya.com/blog/2021/12/step-by-step-guide-to-build-image-caption-generator-using-deep-learning/)
- [Image/Video Summarization in Text/Speech for Visually Impaired People](https://ieeexplore.ieee.org/document/9972653)
- [Audio Description of Videos for People with Visual Disabilities](https://www.researchgate.net/publication/304189394_Audio_Description_of_Videos_for_People_with_Visual_Disabilities)
- [Artificial intelligence for visually impaired](https://www.sciencedirect.com/science/article/pii/S0141938223000240)
- [What Makes Videos Accessible to Blind and Visually Impaired People?](https://dl.acm.org/doi/10.1145/3411764.3445233)
